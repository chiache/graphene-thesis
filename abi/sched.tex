\subsection{CPU Scheduling}
\label{sec:abi:thread}

\issuedone{1.2.a}{discuss resource management at host level (threading)}
The host ABI for CPU scheduling includes two abstractions:
one is the creation of a {\bf thread}, an execution unit allocated by the guest,
to be scheduled to run on a CPU core.
The other abstraction is a set of {\bf scheduling primitives},
designed for synchronization and coordination
among multiple threads.
%Both Linux and POSIX have defined a rich threading API, with various thread creation options
%and complex scheduling primitives.
%\graphene{} simplifies the host ABI
%by include only a small set of basic threading features.
%for each host to implement.



The thread abstraction requires the host OS to contain a host scheduler.
A host scheduler will dynamically assign one of the living threads to each CPU core, to allow the thread to continue execution until rescheduling.
The scheduling algorithm of a host scheduler is up to
the design and configuration of the host OS;
however, a host scheduler does have to ensure every thread to follow its expected behaviors,
regardless of the scheduling algorithm.
For the least, a host scheduler should avoid completely starving one of the living threads,
so that the guest can make progress as expected.
Other CPU scheduling criteria such as fairness, throughput, and CPU utilization
are still critical to the application performance, but the host scheduler is responsible of improving these criteria.






\subsubsection*{Creating or terminating a thread}



%Unlike a user thread in Linux or POSIX (i.e., a ``pthread''),
%a guest thread created by the host ABI,
%using \palcall{ThreadCreate},
%is simply a new context which starts at a function.
%The host ABI
%moves all the thread creation options,
%such as thread-local storage,
%to an initialization function called after the thread creation,
%inside the library OS.
%The purpose of \palcall{ThreadCreate}
%is simple: it creates a ``kernel thread'' in the host,
%which can be scheduled by the host scheduler,
%to run application code on another CPU core.
%The \graphene{} library OS does not implement its own scheduler.


\begin{paldef}
HANDLE ThreadCreate (void (*start) (void *),
                     void *param);
\end{paldef}


\palcall{ThreadCreate} creates a living thread that can be immediately
scheduled by the host scheduler.
The arguments of \palcall{ThreadCreate} specify the initial state of the new thread, including a function to start the thread execution, and a parameter being passed to the function.
As soon as \palcall{ThreadCreate} successfully returns,
the caller thread and the created thread should both be live in the host OS.
%and scheduled to run in arbitrary order.
When \palcall{ThreadCreate} succeeds, it returns a thread handle that represents the created thread
to the caller.




\palcall{ThreadCreate} is simplified in several ways.
First, \palcall{ThreadCreate} does not allow the guest to specify
the initial stack where the new thread starts execution.
Instead, the host OS takes the liberty of allocating an initial, fixed-size stack for the new thread,
but the new thread is free to
switch to a user-assigned stack afterward.
Second, \palcall{ThreadCreate} takes no creation options
except a starting function and a parameter.
Every threads created by \palcall{ThreadCreate} should look identical to the host,
and share every resources assigned to the process.



\begin{paldef}
void ThreadExit (void);
\end{paldef}

\palcall{ThreadExit} simply terminates the current thread in the host OS. The \hostapi{} takes no argument, and should never return if it succeeds.
The purpose of \palcall{ThreadExit} is to free the resources allocated in the host OS
for creating the current thread, including the initial stack.




%The host ABI does not implement thread exiting notifications.
%When a guest thread is terminated using \palcall{ThreadExit}, the PAL destroys the correspondent kernel thread
%without notifying other threads.
%The design counts on the library OS to implement the Linux-style notifications,
%including
%sending a \code{SIGCHLD} signal,
%or triggering a parent-wakening futex.
% assigned by a child thread ID field given to  


\subsubsection*{Scheduling a thread}


The host ABI allows a running thread to voluntarily give up the CPU core,
or to be interrupted by other threads.
In either ways, the thread is suspended until being rescheduled
to a CPU core.
The purpose of rescheduling a thread is to prevent the thread to busily waiting for a specific condition,
such as a variable being set to specific value, or a specific time in the future.
Busy-waiting wastes CPU cycles,
and can potentially prevent other threads from being scheduled, if the host scheduler does not
implement a time-slicing scheduling algorithm such as round-robin.
Although the guest delegates scheduling to the host scheduler, the guest can proactively request for scheduling to improve CPU throughput.



%Besides thread creation,
%the host ABI needs scheduling features to interrupt a thread execution,
%or yield the CPU.
%The concerns for including scheduling features
%in the host ABI
%is two-fold.
%The first concern is regarding compatibility;
%an application may be stuck in a busy-waiting loop, if the library OS lacks the ability to interrupt the execution when certain events occur.
%Specifically, \palcall{ThreadInterrupt} interrupts a thread using a thread handle
%returned by \palcall{ThreadCreat}.
%The second concern is regarding the CPU occupancy;
%if a thread does not forfeit the CPU when it stops making progress,
%the CPU can be wasted being idle.
%\palcall{ThreadDelay} and \palcall{ThreadYield}
%delays the current thread, until a period of time has passed, or the host scheduler re-schedules the thread to a CPU core.



\begin{paldef}
u64  ThreadDelay     (u64 delay_microsec);
void ThreadYield     (void);
\end{paldef}


\fixmedp{Define the semantics a bit more. When you do a delay, presumably wait at least that long; are theere any cases you can return early (e.g., EINTR)?}
Both \palcall{ThreadDelay} and \palcall{ThreadYield} suspend the current thread for rescheduling.
\palcall{ThreadDelay} suspends the current thread
for a period of time, and the length of suspension is specified by \palkeyword{delay_microsec}, in microseconds.
If the thread is suspended successfully and rescheduled after expiration of the specified period,
\palcall{ThreadDelay} returns zero and resumes the thread execution.
If the thread is rescheduled prematurely, due to interruption of other threads (using \palcall{ThreadInterrupt}),
\palcall{ThreadDelay} returns the remaining suspension time in microseconds.


\fixmedp{When you do a yield, under what conditions are you rescheduled?}
\palcall{ThreadYield} simply yields the execution of current thread, and the thread can be rescheduled immediately by the host scheduler.
\palcall{ThreadYield} allows a thread to request for rescheduling when the thread expects
to wait for certain conditions.
When \palcall{ThreadYield} is called, the host scheduler will suspend the current time slice,
and rerun the scheduling algorithm to select a runnable thread.








\begin{paldef}
void ThreadInterrupt (HANDLE thread_handle);
\end{paldef}



\palcall{ThreadInterrupt} reschedules another thread, either running or suspended, based on a given thread handle.
\palcall{ThreadInterrupt} has two primary purposes.
First, \palcall{ThreadInterrupt} can interrupt the suspension of a thread, and force the thread to resume execution immediately.
Second, \palcall{ThreadInterrupt} can interrupt the execution of a running thread,
so that the thread can instantaneously respond to a sudden event.
Without \palcall{ThreadInterrupt},
a running thread can only detect the occurrence of an event at a certain ``checkpoint'' in the code.





\paragraph{Scheduling options.}
The host ABI currently contains no scheduling options for the guest to configure the host scheduler.
An OS usually allows an application to set certain scheduling options,
such as assigning the scheduling priority of a thread, or configuring the scheduling policies.
For simplicity,
the host ABI completely delegates scheduling to the host scheduler,
and only allows host-level, user configuration for setting the scheduling options statically.
The simplicity prevents the host from exposing a wide interface
for configuring the host scheduler,
but such a host ABI would fail to support
most of the scheduling options available in Linux (e.g., \syscall{sched\_setparam}).
%Similar to memory management, the host ABI delegates scheduling to the hosts.
%As the design and implementation of the scheduling policies
%differ from host to host,
%the library OS cannot implement all the Linux scheduling API and policies in the user space,
%unless the host ABI exposes a wide interface
%for configuring the host scheduler.



Luckily, most of the scheduling options in Linux does not impact
the functionality of an application.
For example, without setting the scheduling priority,
the application can still make progress,
but may suffer performance penalty due to unnecessary CPU idles.
The only exception is CPU affinity, as binding a thread to one or multiple CPU cores.
CPU affinity is important
for an application with a producer-consumer programming model,
wherein the consumer busily waits for the producer.
Such a producer-consumer model requires the producer and consumer threads to be scheduled on different CPU cores, to prevent being deadlocked by the scheduler.
% when an application requires
%producer and consumer threads
%to be scheduled on different cores,
%or the application may be deadlocked and stop progressing.
%which continues to poll a work queue;
%in this producer-consumer scenario,
%the threads must run on different CPU cores, to prevent deadlocks.
We propose adding a \hostapi{} called \palcall{ThreadSetCPUAffinity}
to support binding a thread to CPU cores:

\begin{paldef}
bool ThreadSetCPUAffinity (u8 cpu_indexes[], u8 num);
\end{paldef}

\fixmedp{Explain how the arguments work}
\palcall{ThreadSetCPUAffinity} binds the current thread to a list of CPU cores, as specified in \palkeyword{cpu_indexes}.
\palkeyword{cpu_indexes} is an array of non-negative integers, which are smaller than the total number of CPU cores.



\subsubsection*{Scheduling primitives}


The host ABI includes two scheduling primitives: one is mutex locking, and the other is a waitable event.
The purpose of defining the host scheduling primitives
is to improve the user-space locking. The user-space locking is generally implemented
by atomic instructions
or the compare-and-swap (CAS) instruction;
To perform user-space locking, a thread will be spinning on a CPU core until atomically changing the state of a lock or an event.
The host scheduling primitives can prevent a thread from spinning on a CPU core,
by requesting the host scheduler
to suspend the thread until the expected condition occurs.





%, for synchronizing the execution
%of several threads running in parallel.
%The host ABI must provide scheduling primitives,
%because locking cannot be reliably implemented in the user space;
%user-space locking
%cannot prevent a thread from being interrupted inside a critical section,
%and thus 
%causing the application to deadlock.
%Also, user-space locking must be implemented using the compare-and-exchange (\code{CMPXCHG}) instructions, which may not be available on every architectures.
%Therefore, by including the scheduling primitives in the host ABI,
%\graphene{} can encapsulate different kinds of scheduling options available on the hosts.



\begin{paldef}
HANDLE MutexCreate (void);
void   MutexUnlock (HANDLE mutex_handle);
\end{paldef}


\palcall{MutexCreate} creates a mutex (mutually-exclusive) lock for atomic execution of a critical section in the code.
A mutex lock can only be acquired by one thread at a time;
if multiple threads are competing over a mutex lock, only one thread will proceed while other threads will block until the lock is released.
A mutex lock can be acquired by \palcall{ObjectsWaitAny} (defined later),
and be released by \palcall{MutexUnlock}.



\begin{paldef}
HANDLE SynchronizationEventCreate (void);
HANDLE NotificationEventCreate    (void);
void   EventSet   (HANDLE event_handle);
void   EventClear (HANDLE event_handle);
\end{paldef}



%\graphene{} inherit most of the scheduling primitives
%from \drawbridge{}~\cite{porter11drawbridge}:
%{\bf semaphores} ensures the atomicity of a critical section;
%{\bf events} enforces the order of execution among multiple threads.
%The events created by the host ABI
%can be separated into synchronization events and notification events;
%the former is used by a producer thread, to wake a consumer thread
%blocking on a queue;
%the latter notifies the occurrence of a condition
%and prevent further blocking of threads.
%Both semaphores and events resemblance the abstractions provided by the Windows API;
%we show that these scheduling primitives are also portable on other hosts, including Linux, BSD, and SGX, using futexes or similar locking mechanisms.



\palcall{SynchronizationEventCreate} and \palcall{NotificationEventCreate} create two different types of waitable events for synchronizing the execution of multiple threads.
Both types of events can be signaled by a thread.
Signaling a synchronization event allows exactly one waiting thread to continue execution.
A synchronization event can synchronize producer and consumer threads,
since a producer thread can signal exactly one consumer at a time.
On the other hand, a notification event can stay signaled until a thread manually resets the event using \palcall{EventClear}.
A notification event can be used for notifying the occurrence of a one-time event,
such as the start of a new thread.
%Both types of events can be waited by a thread. %, using \palcall{ObjectsWaitAny}.
%The difference is that
%singaling a synchronization event
%wakes up at most one thread that are currently waiting for the event,
%whereas signaling a notification event stops any thread from
%further blocking on the event.
An event can be signal by \palcall{EventSet}, and a thread can wait for the event
using \palcall{ObjectsWaitAny} (defined later).


%Synchronization events and notification events are designed for different purposes.
%A synchronization event can be used in a producer-consumer model, wherein a consumer thread can block until a producer thread signals the event.
%On the other hand, a notification event can be used for notifying the occurrence of a one-time event;
%for example, a thread calling \palcall{ThreadCreate} can use a notification event to block until a new thread is created and starts execution.


\subsubsection*{Waiting for scheduling events}


%The host ABI allows the library OS to poll one or several handles
%at the same time.
%The possible handles to poll include semaphores, synchronization or notification events,
%or I/O streams.
%Therefore, the host ABI
%introduces a function, \palcall{ObjectsWait}, similar to \syscall{poll} in POSIX,
%with a timeout option.



\begin{paldef}
HANDLE ObjectsWaitAny (HANDLE *handles, u8 nhandles,
                       u64 timeout);
\end{paldef}


\palcall{ObjectsWaitAny} will block on one or multiple event handles, until one of the events occur.
For the least,
\palcall{ObjectsWaitAny} allows a thread to
wait until a mutex lock is released, or an event is signaled.
Moreover, \palcall{ObjectsWaitAny} can be used to poll %for certain events
an I/O stream handle,
to wait for events such as arrival or delivery of data,
a stream being shut down.
\palcall{ObjectsWaitAny}




\begin{paldef}
HANDLE StreamGetEvent (HANDLE stream_handle,
                       u16 event_flags);
\end{paldef}


A challenge to implementing polling
to differentiate the I/O events which can occur on a stream.
When blocking on a network or RPC stream, an application needs to be notified
about three types of events:
establishment of the connection (i.e., becoming writable), arrival of messages (i.e., becoming readable), and shut-down of the connection;
thus, the \graphene{} host ABI introduces a new function,
\palcall{StreamGetEvent},
to generate a handle identifying these I/O events of a stream,
and can be polled by \palcall{ObjectsWait}.
The design also keeps the definition of \palcall{ObjectsWait} simple:
\palcall{ObjectsWait} should do nothing more than blocking on an array of handles,
until one of the handles
is wakened, or the call timeouts.


\subsubsection*{Thread-local storage}


Most OSes requires thread-local storage (TLS),
either to implement thread-private application variables, or to store thread-specific, system library states, in a thread control block (TCB).
Because thread-local storage can be frequently accessed
in an application,
it would be inefficient to constantly
enter the kernel for retrieving the TLS data.
A common design is to occupy one of the thread-private registers
to store a pointer to the thread-local storage;
on \graphenearch{}, the FS register is commonly used to reference the thread-local storage.




\begin{paldef}
void SegmentRegSet (uint register, ulong *value);
\end{paldef}



\issuedone{1.3.e}{discuss the FS/GS limitation}
The host ABI includes a function, \palcall{SegmentRegSet}, to set the FS/GS registers.
The implementation of \palcall{SegmentRegSet}
depends the host system interfaces. 
By default, reading or writing the value of the FS/GS registers is a privileged operation
which can only be performed in ring 0.
On Linux or BSD, the FS register is commonly used for bookkeeping in the standard C library;
thus, the Linux or BSD system calls naturally include the feature of reading or writing the FS/GS registers in the kernel space (although only the FS register is used in the user space).
However, on other hosts, especially Windows and OSX,
we observe the case where changing the FS/GS registers is considered unnecessary and dangerous to the kernel.
These hosts periodically reset the value of the FS/GS registers,
preventing the host ABI to assign the TLS permanently.


The primary challenge
to implementing TLS for Linux applications
is that an executable can hard-code the references to the FS register in its binary.
Because a Linux executable is usually {\em unrelocatable},
it can access a thread-private pointer by simply reading or writing to a specific offset
to the FS register.
To support these applications,
a host must populate a valid TCB at the address pointed by the FS register;
if the host forbids setting the FS register,
the library OS cannot support TLS for an executable using thread-private pointers.

%On these hosts, the compatibility for TLS usage in applications is partially sacrificed.



\subsection{Processes}
\label{sec:abi:proc}


\graphene{} implements a distributed OS model for multi-process applications.
Each process in \graphene{} has a library OS instance;
Multiple library OS instances in a multi-process application must work together
to present a single OS view,
same as running in a native Linux.
Therefore, the host ABI does not require copy-on-writing forking,
but simply creation of a clean process instantiating the library OS.




\begin{paldef}
HANDLE ProcessCreate (const char *executable,
                      const char *manifest,
                      const char **args, uint flags);
\end{paldef}

When creating a process, the host ABI, as \palcall{ProcessCreate}, takes a URI of the executable to run in the new process,
together with a manifest file, which specifies the user policy.
Once a new process is created, the library OS can be initialized
and migrate the library OS and application state from the parent process;
after migration, the new process can resume execution from the point of checkpointing,
as a forked process.
To the hosts, the processes in an application share nothing
but the I/O streams opened by multiple processes.


\palcall{ProcessCreate} returns a process handle.
To bootstrap the inter-process communication, a process handle also works as an unnamed RPC stream connecting the parent and child processes.
The initialization of a library OS instance uses the RPC stream
to retrieve namespace coordination information, such as how to locate the namespace leaders.
The PRC stream is also used to send process migration data
from the parent process, to implement forking.






\subsubsection*{Sharing a handle}




Due to the statelessness of stream handles,
a library OS can cleanly migrate its state to a new process, and recreate all the stream handles previously opened in the process.
Unfortunately, not all I/O streams can be recreated
in a new process, due to the limitations of host system interfaces;
in most hosts, a network connection is only identified by one handle or file descriptor,
and can only be shared when the handle or file descriptor
is inherited by a child process.
The same inheritance feature also has to be implemented
inside the library OS, to support Linux applications.
Since every process created by \palcall{ProcessCreate} is a clean \graphene{} process with freshly-initialized library OS state,
the library OS needs extra functions in the host ABI
to inherit handles instead of data from the parent process.


\begin{paldef}
void   RpcSendHandle (HANDLE rpc_handle, HANDLE cargo);
HANDLE RpcRecvHandle (HANDLE rpc_handle);
\end{paldef}



The host ABI introduces two functions for sharing handles across processes: \palcall{RpcSendHandle} and \palcall{RpcRecvHandle}, which sends handles over a connected RPC stream.
The design is motivated by the Linux file descriptor sharing feature of UNIX domain sockets.
\palcall{RpcSendHandle} will migrate the state of a stream handle, created by \palcall{StreamOpen},
over a RPC stream, to the receiving process, which calls \palcall{RpcRecvHandle}.
\palcall{RpcSendHandle} will grant the receiving process the permission, to share the stream handle with the sending process.


\subsubsection*{Bulk IPC (physical memory store)}


Migrating and coordinating process states over RPC streams
can suffer significant overhead, when copying large chunks of memory.
Especially, the RPC-based migration will slow down the latency of copy-on-write forking.
%the key overhead
%is caused by copying large chunk of memory
%across processes, without the help of a host to share the physical memory.

\begin{paldef}
HANDLE PhysicalMemoryStore  (uint index);
ulong  PhysicalMemoryCommit (HANDLE store_handle,
                             void *addr, ulong size);
void * PhysicalMemoryMap    (HANDLE store_handle,
                             void *addr, ulong size,
                             uint protection);
\end{paldef}


The host ABI introduces a Bulk IPC feature, for reducing the latency of forking.
The main abstraction of Bulk IPC
is a physical memory store (created by \palcall{PhysicalMemoryStore});
To migrate a process, the library OS
can send application memory to the physical memory store (using \palcall{PhysicalMemoryCommit}), which will keep a snapshot of the memory, set as copy-on-write.
The child process can then attach to the physical memory store,
and map the memory snapshot into its memory (using \palcall{PhysicalMemoryMap}).
The Bulk IPC feature can large reduce the amount of physical memory copied during process migration,
and thus optimize the latency of forking.




\subsubsection*{Sandboxing}


The security isolation of \graphene{} is based on a {\bf sandbox}, a container isolating a number of coordinating library OS instances.
When \graphene{} launches an application, the application begins running inside a standalone sandbox.
By default, a new process cloned by the application share the sandbox
with its parent process.
To configure the isolation policies,
developers provide a {\bf manifest} file for each application.
The policies are enforced by a reference monitor in the host.
A manifest file contains run-time rules for sandboxing resources which can be shared in the host,
including files, network sockets, and RPC streams.



Sandboxing delegates
security isolation to the host.
An application doesn't have to trust the library OS
to enforce security policies,
on every applications running on the same host.
If a library OS instance is compromised by the application,
the threat will be contained inside the sandbox,
and cannot cross the sandbox boundary, unless the host is also compromised.
For each sandbox,
the isolation policies are statically assigned,
in the manifest file given at the launch.
The isolation policies
cannot be subverted during execution.



However, sometimes, an application may want to reassign the policies,
for security isolation inside of the application.
Processes in an application may have different privilege levels, or belong to different sessions which should be isolated from each other.
\palcall{SandboxSetPolicy} can dynamically
assign a new manifest file specifying a stricter policy
than the original manifest,
to restrict a process from accessing the resources shared by other processes.
\palcall{SandboxSetPolicy}
moves a process to a new sandbox.
An option, \palkeyword{sandbox_rpc}, can block all RPC streams from other processes running in the original sandbox.







\begin{paldef}
bool SandboxSetPolicy (const char *sandbox_manifest,
                       bool sandbox_rpc);
\end{paldef}



