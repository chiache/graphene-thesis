This chapter evaluates the performance and security of the \graphene{} \libos{} on both the Linux and SGX host.
For both hosts,
the evaluation includes the overhead on start-up times, memory footprints, server throughputs and command-line program latencies, and micro-benchmark results regarding \linuxapi{} overheads.
The evaluation on the Linux host also includes a study of Linux kernel vulnerabilities contained by \graphene{}.
The evaluation on the SGX host includes a summary of trusted computing base (TCB) that \graphenesgx{} adds to an enclave, in lines of code (LoC).

All experiment results are collected on a Dell Optiplex 790 Small-Form Desktop,
with a 4-core 3.2GHz Intel Core i5-6500 CPU (no hyper-threading, with 256KB I-Cache/D-Cache, 1MB L2 Cache, 6MB L3 Cache),
two 4GB DIMM DDR3 1600MHz RAMs (8GB in total), and a Seagate 512GB, 7200 RPM SATA disk formatted as EXT4.
The Intel CPU is configured with Intel SGX and EPT (Extended Page table) enabled, and 128MB enclave page cache (EPC) size.
To prevent fluctuated benchmarking results,
Turbo Boost, SpeedStep, and CPU idle states are disabled for
all experiments.
%We disable SpeedStep and TurboBoost to prevent interference.
All networked servers are evaluated through Intel I219-V 1Gbps Ethernet cards connected to a dedicated local network.




The host OS is Ubuntu 16.04.4 LTS, with Linux kernel 4.10.0.
We use version 1.9 of 
the Intel \sgx{} Linux SDK~\cite{intel-sgx-linux-sdk} and driver~\cite{intel-sgx-linux-driver}.



%Except for scalability measurements, 
%all measurements were collected on a 
%Dell Optiplex 790 with 
%a 4-core 3.40 GHz Intel Core i7 CPU,
%4 GB RAM, and a 250GB, 7200 RPM ATA disk.
%Our host system runs Ubuntu 12.04 server with host Linux kernel version 3.5, 
%which includes KVM on 
%QEMU version 1.0.
%%Adding more detail of KVM environment
%Each KVM Guest is deployed with 4 virtual CPU with EPT, 2GB RAM, a 30GB virtual disk image, Virtio enabled for network and disk, bridged connection with TAP, and runs the same Ubuntu and Linux kernel image.
%We note that recent library OSes are either not openly available
%or cannot execute unmodified Linux binaries.
%Unless otherwise noted, \graphene{} measurements include the reference monitor.
%%In order to assess the relative overhead of the monitor (\S\ref{sec:eval:micro}), 
%%we include some microbenchmark measurements with and without the monitor.





\section{Performance Evaluation}
\label{sec:eval:perf}



%\fixmedp{Missing back-of-the envelope for fork overheads, fraction of system calls using ipc}


This section evaluates \graphene{}'s multi-process coordination, security, cross-host migration, memory footprint, and performance.
We drive this evaluation with a selection of real-world applications that leverage multiple processes in \graphene{},
as well as with microbenchmarks and stress tests.
We organize the evaluation around the following questions:
\begin{compactenum}
	\item How do \graphene{}'s startup and migration costs compare to running an application in a dedicated VM?
	\item Given that RAM is often the limiting factor in VMs per system, how does \graphene{}'s memory footprint compare to other virtualization techniques?
	\item What are the performance overheads of \graphene{} relative to a native Linux process or VM?
	\item What additional overheads are added by the reference monitor?
	\item How do \graphene{}'s overheads scale with the number of processes in a sandbox?
	\item Does the \graphene{} reference monitor enforce security isolation comparable to running the application in a VM?  
	\item What fraction of recent Linux vulnerabilities would \graphene{} prevent?
\end{compactenum}

%We note that no recent single-process library OSes are both publicly available
%and able to execute unmodified Linux binaries.



%We evaluate the performance overheads on running unmodified Linux applications
%on SGX.
%Unlike the existing \sgx{} shielding systems which focuses on cloud-based systems or microservices,
\graphenesgx{} is designed to be general-purpose, supporting a broad range of
server and command-line applications. 
%, including both server and desktop workloads.
%\fixmedp{I wouldn't really call gcc or R ``desktop''}
\fixme{get rid of the part that we need to compile source code}
We thus evaluate performance overheads of unmodified Linux applications, using binaries 
from an Ubuntu installation.
%, or,
%in the case of Apache, Lighttpd, and NGINX,
%compiled from original source code using the default configurations.}
%(Apache, Lighttpd, and NGINX are compiled from source).} %\fixmedp{which apps are compiled?}
Depending on the workload, we measure application throughput or latency.
%According to the types of workloads, we design experiments to evaluate whether \graphenesgx{} can support applications with acceptable throughput or latency.

%All applications in our experiments are real, unmodified Linux applications,
%either directly taken from a disk with Ubuntu installation,
%or compiled using the default configuration given by the developers.
%No source code modification or change of compilation environment is required in the experiments.
%In our experiments, we either test on application binaries taken off-the-shelf from the Ubuntu {\tt APT} repositories,
%or applications that are built from the default configurations
%provided by the developers.
%Either source code modification or adjustment of the compilation environment is avoided in the setup of experiments.
%Our evaluation simulates the realistic results of running unmodified Linux applications in \graphenesgx{}.
%running Linux COTS applications on commodity hardware.

In order to differentiate SGX-specific overheads 
from Graphene overheads,
%, which also
%runs on a Linux host without SGX, 
we use both
Linux processes and \graphene{} on a Linux host without SGX as baselines
for comparison.
%Since a large portion of the \libos{} design is inherited from the \graphene{} \libos{},
%the performance impact of adopting \graphenesgx{} is largely affected by the design choices made in \graphene{}.
%In order to show the performance impact of \graphenesgx{} over \graphene{}, we use both native Linux and \graphene{} on a Linux host as the baselines for comparison.
Note that \graphene{} includes two optional kernel extensions:
one that creates a reference monitor to protect the host kernel from 
the library OS, and one that optimizes fork by 
with copy-on-write for large (page-sized) RPC messages.
%implementing a multi-page RPC
%abstraction.
Neither of these extensions are currently supported in \graphenesgx{}.
%so we measure baseline Graphene with these disabled.
% can be optionally run with a reference monitor for security isolation, and a bulk IPC abstraction for fork optimization.
%Since neither of the features is ported in \graphenesgx{},
%we mostly compare \graphenesgx{} to \graphene{} with these two features disabled,
%to show a more meaningful comparison.